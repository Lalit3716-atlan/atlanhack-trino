name: E2E Integration Test
on:
  push:
    branches:
      - main
      - develop
      - nishrefactor # TODO: remove this after refactoring is done
  pull_request:
    types:
      - opened
      - synchronize
    branches:
      - main
      - develop
      - nishrefactor # TODO: remove this after refactoring is done
  workflow_dispatch:
    inputs:
      distinct_id:

jobs:
  test:
    runs-on: ubuntu-latest
    concurrency:
      group: ${{ github.workflow }}-${{ github.ref }}
      cancel-in-progress: ${{ startsWith(github.ref, 'refs/pull/') }}
    timeout-minutes: 10
    permissions:
      pull-requests: write
      contents: write

    steps:
    - name: echo distinct ID ${{ github.event.inputs.distinct_id }}
      run: echo ${{ github.event.inputs.distinct_id }}

    - uses: actions/checkout@v4.0.0
      with:
        token : ${{ secrets.ORG_PAT_GITHUB }}

    # Install Dapr
    - name: Install Dapr CLI
      run: |
        wget -q https://raw.githubusercontent.com/dapr/cli/master/install/install.sh -O - | /bin/bash -s 1.14.1
        dapr init --runtime-version 1.13.6 --slim

    # Install Temporal
    - name: Install Temporal CLI and Start Server
      run: |
        curl -sSf https://temporal.download/cli.sh | sh
        export PATH="$HOME/.temporalio/bin:$PATH"
        temporal server start-dev --db-filename /tmp/temporal.db &
        sleep 5

    - uses: atlanhq/application-sdk/.github/actions/setup-deps@main

    - name: Update application-sdk rev
      if: ${{ github.event.inputs.distinct_id != '' }}
      run: |
        commit_hash=${{ github.event.inputs.distinct_id }}
        uv add git+https://github.com/atlanhq/application-sdk --rev $commit_hash

    # Download components and start dapr and temporal services
    - name: Start Platform Services
      run: |
        uv run poe download-components
        uv run poe start-deps
        # Wait for Dapr sidecar to be ready
        sleep 5

    # Start the application
    - name: Start the application
      id: start_app
      env:
        ATLAN_SQL_SERVER_MIN_VERSION: "10.0"
      run: |
        uv run scalene --profile-all --cli --outfile ./.github/scalene.json --json main.py &
        sleep 20

    - name: Run the end-to-end integration tests
      env:
        E2E_POSTGRES_HOST: ${{ secrets.POSTGRES_DB_HOST }}
        E2E_POSTGRES_PORT: 5432
        E2E_POSTGRES_USERNAME: "postgres"
        E2E_POSTGRES_PASSWORD: ${{ secrets.POSTGRES_DB_PASSWORD }}
        ATLAN_SQL_SERVER_MIN_VERSION: "10.0"
      run: |
        uv run coverage run -m pytest tests/e2e

    - name: Get scalene metrics and output
      run: |
        export PATH="$HOME/.temporalio/bin:$PATH"
        kill $(lsof -t -i :8000) || true
        sleep 10

        # Calculate metrics from current run's scalene.json
        if [ -f .github/scalene.json ]; then
          # Calculate Average CPU Usage upto 2 decimal places
          AVG_CPU=$(jq -r '
            [
              .files |
              to_entries[] |
              .value.functions[] |
              select(.n_cpu_percent_c != null and .n_cpu_percent_python != null and .n_sys_percent != null) |
              (.n_cpu_percent_c + .n_cpu_percent_python + .n_sys_percent)
            ] |
            add / length
          ' .github/scalene.json | awk '{printf "%.2f\n", $1}')

          # Max CPU Usage upto 2 decimal places
          MAX_CPU=$(jq -r '
            .files |
            to_entries[] |
            .value.functions[] |
            select(.n_cpu_percent_c != null and .n_cpu_percent_python != null and .n_sys_percent != null) |
            (.n_cpu_percent_c + .n_cpu_percent_python + .n_sys_percent)
          ' .github/scalene.json | sort -rn | head -n1 | awk '{printf "%.2f\n", $1}')

          MEMORY_USAGE=$(jq -r '
            .max_footprint_mb
          ' .github/scalene.json | awk '{printf "%.2f\n", $1}')
        else
          echo "Current scalene.json does not exist"
          AVG_CPU="N/A"
          MAX_CPU="N/A"
          MEMORY_USAGE="N/A"
        fi

        echo "Finished Calculating Metrics"

        # Generate comprehensive report
        echo "## ðŸ“Š Postgres App Integration Test Results and Performance Metrics" >> metrics.md
        echo "### Runner Environment Details" >> metrics.md
        echo "$(mpstat 1 1 | awk 'NR == 1')" >> metrics.md
        echo "Total Memory: $(free -m | awk 'NR == 2 {print $2}') MB" >> metrics.md

        echo "### ðŸ“Š Resource Usage" >> metrics.md
        echo "| Metric | Value |" >> metrics.md
        echo "|--------|-------|" >> metrics.md
        echo "| Average CPU Usage | $AVG_CPU% |" >> metrics.md
        echo "| Max CPU Usage | $MAX_CPU% |" >> metrics.md
        echo "| Memory Usage | $MEMORY_USAGE MB |" >> metrics.md

        echo "---" >> metrics.md

        cat metrics.md
        exit 0

    - name: Comment integration test profiling status on Pull Request
      if: ${{ github.event_name == 'pull_request' }}
      uses: mshick/add-pr-comment@b8f338c590a895d50bcbfa6c5859251edc8952fc # v2.8.2 https://github.com/mshick/add-pr-comment/releases/tag/v2.8.2
      with:
        message-id: "integration_test_profiling"
        message-path: metrics.md
      continue-on-error: true

    # Stop all services
    - name: Stop all services and monitoring
      if: always()
      run: |
        # Kill monitoring process first
        pkill -f "mpstat" || true
        # Stop the application and services gracefully
        uv run poe stop-deps || true